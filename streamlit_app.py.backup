"""
Streamlit Web App for Vector Database Visualization

Run with: streamlit run streamlit_app.py
"""

import streamlit as st
import sys
from pathlib import Path
from collections import Counter
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

from src.vector_store.chroma_manager import ChromaDBManager
from src.embeddings.embedder import Embedder
from src.embeddings.model_registry import get_model_registry


# Page config
st.set_page_config(
    page_title="Vector DB Viewer",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state
if 'collection' not in st.session_state:
    with st.spinner("Loading vector database..."):
        manager = ChromaDBManager()
        st.session_state.collection = manager.get_or_create_collection()
        st.session_state.total_docs = st.session_state.collection.count()

# Initialize model selection
if 'selected_model' not in st.session_state:
    # Get available models from registry
    try:
        registry = get_model_registry()
        available_models = registry.get_registered_models()
        if available_models:
            st.session_state.selected_model = available_models[0]  # Default to first model
        else:
            st.session_state.selected_model = "BAAI/bge-large-en-v1.5"  # Fallback
    except Exception as e:
        st.session_state.selected_model = "BAAI/bge-large-en-v1.5"  # Fallback
        st.error(f"Could not load model registry: {e}")

# Initialize app mode
if 'app_mode' not in st.session_state:
    st.session_state.app_mode = "Database Explorer"

# Initialize processing state
if 'processing_state' not in st.session_state:
    st.session_state.processing_state = {
        'is_processing': False,
        'current_phase': None,
        'progress': 0,
        'status_message': '',
        'errors': []
    }

# Initialize file selection
if 'selected_files' not in st.session_state:
    st.session_state.selected_files = []

# ============================================================================
# SIDEBAR
# ============================================================================

st.sidebar.title("üéõÔ∏è Control Panel")

# Navigation
st.session_state.app_mode = st.sidebar.radio(
    "Select Mode:",
    ["üìÅ Data Processing", "üîç Database Explorer"],
    index=1 if st.session_state.app_mode == "Database Explorer" else 0,
    help="Switch between data processing and database exploration"
)

st.sidebar.markdown("---")

# ============================================================================
# SIDEBAR SECTION 1: DATA PROCESSING
# ============================================================================
if st.session_state.app_mode == "üìÅ Data Processing":
    st.sidebar.subheader("üìÅ Data Processing")
    
    # Model selection
    st.sidebar.markdown("### ü§ñ Embedding Model")
    try:
        registry = get_model_registry()
        available_models = registry.get_registered_models()

        if available_models:
            # Create model selector
            model_options = {model: model for model in available_models}
            selected_model = st.sidebar.selectbox(
                "Model:",
                options=list(model_options.keys()),
                index=list(model_options.keys()).index(st.session_state.selected_model)
                      if st.session_state.selected_model in model_options else 0,
                help="Choose the embedding model for processing"
            )

            # Update session state if changed
            if selected_model != st.session_state.selected_model:
                st.session_state.selected_model = selected_model
                st.rerun()

            # Show model info
            metadata = registry.get_model_metadata(st.session_state.selected_model)
            if metadata:
                st.sidebar.caption(f"""
**{metadata.adapter_class.__name__}**  
üìè Dimension: {metadata.embedding_dimension}  
üìù Max length: {metadata.max_sequence_length}
""")

        else:
            st.sidebar.error("No models available")

    except Exception as e:
        st.sidebar.error(f"Could not load models: {e}")
    
    # Processing configuration
    st.sidebar.markdown("### ‚öôÔ∏è Processing Config")
    
    batch_size = st.sidebar.slider(
        "Batch size:",
        min_value=8,
        max_value=128,
        value=32,
        step=8,
        help="Number of chunks to process at once"
    )
    
    max_workers = st.sidebar.slider(
        "Max workers:",
        min_value=1,
        max_value=8,
        value=4,
        help="Parallel processing workers"
    )
    
    skip_duplicates = st.sidebar.checkbox(
        "Skip duplicates",
        value=True,
        help="Skip already processed videos"
    )
    
    parallel_processing = st.sidebar.checkbox(
        "Parallel preprocessing",
        value=True,
        help="Use parallel processing for preprocessing"
    )

# ============================================================================
# SIDEBAR SECTION 2: DATABASE EXPLORER
# ============================================================================
elif st.session_state.app_mode == "üîç Database Explorer":
    st.sidebar.subheader("üîç Database Explorer")
    
    # Show current model info
    st.sidebar.markdown("### ü§ñ Current Model")
    try:
        registry = get_model_registry()
        metadata = registry.get_model_metadata(st.session_state.selected_model)
        if metadata:
            st.sidebar.info(f"""
**{st.session_state.selected_model}**  
üìè {metadata.embedding_dimension}D embeddings  
üîß {metadata.adapter_class.__name__}
""")
    except Exception as e:
        st.sidebar.caption(f"Model: {st.session_state.selected_model}")
    
    # Database stats
    st.sidebar.markdown("### üìä Database Stats")
    st.sidebar.metric("Total Documents", st.session_state.total_docs)
    
    # Quick actions
    st.sidebar.markdown("### ‚ö° Quick Actions")
    if st.sidebar.button("üîÑ Refresh Database", use_container_width=True):
        st.session_state.collection = ChromaDBManager().get_or_create_collection()
        st.session_state.total_docs = st.session_state.collection.count()
        st.rerun()

st.sidebar.markdown("---")

# ============================================================================
# MAIN CONTENT
# ============================================================================

# ============================================================================
# MODE 1: DATA PROCESSING
# ============================================================================
if st.session_state.app_mode == "üìÅ Data Processing":
    st.title("üìÅ Data Processing & Vectorization")
    st.markdown("Upload subtitle files and generate embeddings for vector database indexing")
    
    # File Upload Section
    st.header("üì§ Upload Subtitle Files")
    
    col_upload1, col_upload2 = st.columns([2, 1])
    
    with col_upload1:
        uploaded_files = st.file_uploader(
            "Upload SRT files",
            type=['srt'],
            accept_multiple_files=True,
            help="Select one or more .srt subtitle files to process"
        )
        
        if uploaded_files:
            st.success(f"‚úì {len(uploaded_files)} file(s) uploaded")
            
            # Save uploaded files temporarily
            upload_dir = Path("data/raw/subtitles")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            saved_files = []
            for uploaded_file in uploaded_files:
                file_path = upload_dir / uploaded_file.name
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                saved_files.append(file_path)
            
            st.info(f"Files saved to: {upload_dir}")
    
    with col_upload2:
        # Scan existing files
        scan_dir = Path("data/raw/subtitles")
        if scan_dir.exists():
            existing_files = list(scan_dir.rglob("*.srt"))
            st.metric("Files in directory", len(existing_files))
            
            if st.button("üîç Scan Directory", use_container_width=True):
                st.session_state.selected_files = existing_files
                st.rerun()
        else:
            st.metric("Files in directory", 0)
    
    # File Selection Section
    st.header("üìã Available Files")
    
    scan_dir = Path("data/raw/subtitles")
    if scan_dir.exists():
        available_files = list(scan_dir.rglob("*.srt"))
        
        if available_files:
            # Create DataFrame for file list
            file_data = []
            for file_path in available_files:
                file_stat = file_path.stat()
                file_data.append({
                    'Filename': file_path.name,
                    'Size (KB)': f"{file_stat.st_size / 1024:.2f}",
                    'Path': str(file_path),
                    'Select': False
                })
            
            df = pd.DataFrame(file_data)
            
            # File selection
            st.markdown(f"**Found {len(available_files)} SRT files**")
            
            col_sel1, col_sel2, col_sel3 = st.columns(3)
            with col_sel1:
                if st.button("‚úÖ Select All"):
                    st.session_state.selected_files = available_files
                    st.rerun()
            with col_sel2:
                if st.button("‚ùå Clear Selection"):
                    st.session_state.selected_files = []
                    st.rerun()
            with col_sel3:
                max_files = st.number_input("Max files to process:", min_value=1, max_value=len(available_files), value=min(10, len(available_files)))
            
            # Show file table
            st.dataframe(df[['Filename', 'Size (KB)']], use_container_width=True, height=300)
            
            # Manual selection
            with st.expander("üéØ Manual File Selection"):
                selected_indices = st.multiselect(
                    "Select specific files:",
                    options=list(range(len(available_files))),
                    format_func=lambda i: available_files[i].name,
                    default=list(range(min(max_files, len(available_files))))
                )
                st.session_state.selected_files = [available_files[i] for i in selected_indices]
            
            st.info(f"**{len(st.session_state.selected_files)} file(s) selected for processing**")
        else:
            st.warning("No SRT files found in directory. Upload files above.")
    else:
        st.warning(f"Directory {scan_dir} does not exist. Upload files to create it.")
    
    # Processing Section
    st.header("‚ö° Start Processing")
    
    if st.session_state.selected_files:
        col_proc1, col_proc2, col_proc3 = st.columns(3)
        
        with col_proc1:
            st.metric("Files to Process", len(st.session_state.selected_files))
        with col_proc2:
            st.metric("Batch Size", batch_size)
        with col_proc3:
            st.metric("Max Workers", max_workers)
        
        # Processing configuration summary
        with st.expander("üìã Processing Configuration"):
            st.write(f"**Embedding Model:** {st.session_state.selected_model}")
            st.write(f"**Batch Size:** {batch_size}")
            st.write(f"**Max Workers:** {max_workers}")
            st.write(f"**Skip Duplicates:** {skip_duplicates}")
            st.write(f"**Parallel Preprocessing:** {parallel_processing}")
        
        # Start Processing Button
        if not st.session_state.processing_state['is_processing']:
            if st.button("üöÄ Start Processing", type="primary", use_container_width=True):
                st.session_state.processing_state['is_processing'] = True
                st.rerun()
        else:
            st.warning("‚è≥ Processing in progress...")
            
            # Show progress (placeholder for now)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("Processing will be implemented in next step...")
            progress_bar.progress(0)
            
            # Stop button
            if st.button("‚èπÔ∏è Stop Processing", type="secondary", use_container_width=True):
                st.session_state.processing_state['is_processing'] = False
                st.rerun()
    else:
        st.info("üëÜ Select files above to start processing")

# ============================================================================
# MODE 2: DATABASE EXPLORER
# ============================================================================
elif st.session_state.app_mode == "üîç Database Explorer":
    # Main content
    st.title("üìä Vector Database Visualization")
    st.markdown("Explore your subtitle embeddings database interactively")

    # Statistics section
    st.header("üìà Statistics")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Total Documents", st.session_state.total_docs)

    # Get sample for analysis
    sample_size = min(1000, st.session_state.total_docs)
    sample = st.session_state.collection.get(limit=sample_size)

    # Analyze metadata
    video_ids = []
    dates = []
    titles = []

    if sample.get('metadatas'):
        for meta in sample['metadatas']:
            if meta:
                if 'video_id' in meta:
                    video_ids.append(meta['video_id'])
                if 'date' in meta:
                    dates.append(meta['date'])
                if 'title' in meta:
                    titles.append(meta['title'])

    unique_videos = len(set(video_ids)) if video_ids else 0
    avg_chunks = st.session_state.total_docs / unique_videos if unique_videos > 0 else 0

    with col2:
        st.metric("Unique Videos", unique_videos)
    with col3:
        st.metric("Avg Chunks/Video", f"{avg_chunks:.1f}")
    with col4:
        if sample.get('embeddings') and sample['embeddings']:
            emb_dim = len(sample['embeddings'][0])
            st.metric("Embedding Dimension", emb_dim)

# Date distribution chart
if dates:
    st.subheader("üìÖ Date Distribution")
    date_counter = Counter(dates)
    date_df = pd.DataFrame([
        {'Date': date, 'Count': count}
        for date, count in date_counter.most_common(20)
    ])
    
    fig = px.bar(
        date_df,
        x='Date',
        y='Count',
        title="Chunks per Date (Top 20)",
        labels={'Count': 'Number of Chunks', 'Date': 'Date'}
    )
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

# Search section
st.header("üîç Semantic Search")

search_query = st.text_input(
    "Enter your search query:",
    placeholder="e.g., 'how to care for orchids'",
    key="search_input"
)

col_search1, col_search2 = st.columns([3, 1])
with col_search1:
    top_k = st.slider("Number of results:", min_value=1, max_value=20, value=5)
with col_search2:
    st.write("")  # Spacing
    search_button = st.button("üîç Search", type="primary", use_container_width=True)

if search_button and search_query:
    with st.spinner("Searching..."):
        try:
            # Generate query embedding with selected model
            embedder = Embedder()  # Uses model from config, which respects selected_model
            # Note: For now, we use the config model. In Phase 4, we'll implement model-specific collections
            query_embedding = embedder.encode([search_query], is_query=True)[0]
            
            # Search in collection
            results = st.session_state.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k,
                include=['documents', 'metadatas', 'distances']
            )
            
            if results.get('ids') and results['ids'][0]:
                st.success(f"Found {len(results['ids'][0])} results")
                
                # Display results
                for i, (doc_id, doc_text, metadata, distance) in enumerate(zip(
                    results['ids'][0],
                    results['documents'][0],
                    results['metadatas'][0],
                    results['distances'][0]
                ), 1):
                    similarity = 1 - distance
                    
                    with st.expander(
                        f"Result {i}: {metadata.get('title', 'Untitled')[:60]}... "
                        f"(Similarity: {similarity:.3f})",
                        expanded=(i == 1)
                    ):
                        col_meta1, col_meta2 = st.columns(2)
                        with col_meta1:
                            st.write(f"**Video ID:** {metadata.get('video_id', 'N/A')}")
                            st.write(f"**Date:** {metadata.get('date', 'N/A')}")
                        with col_meta2:
                            st.write(f"**Similarity Score:** {similarity:.3f}")
                            st.write(f"**Chunk Index:** {metadata.get('chunk_index', 'N/A')}")
                        
                        st.markdown("---")
                        st.write("**Text:**")
                        st.write(doc_text)
                        
                        # Show similarity bar
                        st.progress(similarity)
            else:
                st.warning("No results found")
        
        except Exception as e:
            st.error(f"Error during search: {e}")
            st.exception(e)

# Document browser section
st.header("üìÑ Document Browser")

# Filter options
col_filter1, col_filter2, col_filter3 = st.columns(3)

with col_filter1:
    browse_limit = st.number_input("Documents to show:", min_value=1, max_value=100, value=10)
with col_filter2:
    filter_video_id = st.text_input("Filter by Video ID (optional):", "")
with col_filter3:
    filter_date = st.text_input("Filter by Date (optional, format: YYYY/MM/DD):", "")

if st.button("üîÑ Load Documents"):
    # Get documents with filters
    all_data = st.session_state.collection.get()
    
    # Apply filters
    filtered_indices = list(range(len(all_data.get('ids', []))))
    
    if filter_video_id:
        filtered_indices = [
            i for i in filtered_indices
            if all_data.get('metadatas', [{}])[i].get('video_id') == filter_video_id
        ]
    
    if filter_date:
        filtered_indices = [
            i for i in filtered_indices
            if all_data.get('metadatas', [{}])[i].get('date') == filter_date
        ]
    
    # Limit results
    filtered_indices = filtered_indices[:browse_limit]
    
    if filtered_indices:
        st.write(f"Showing {len(filtered_indices)} documents")
        
        for idx in filtered_indices:
            doc_id = all_data['ids'][idx]
            doc_text = all_data.get('documents', [''])[idx]
            metadata = all_data.get('metadatas', [{}])[idx]
            
            with st.expander(
                f"Document {idx + 1}: {metadata.get('title', 'Untitled')[:50]}...",
                expanded=False
            ):
                col_doc1, col_doc2 = st.columns(2)
                with col_doc1:
                    st.write(f"**ID:** {doc_id}")
                    st.write(f"**Video ID:** {metadata.get('video_id', 'N/A')}")
                with col_doc2:
                    st.write(f"**Date:** {metadata.get('date', 'N/A')}")
                    st.write(f"**Chunk:** {metadata.get('chunk_index', 'N/A')}")
                
                st.markdown("---")
                st.write("**Text:**")
                st.write(doc_text)
    else:
        st.warning("No documents match the filters")

# Video list section
st.header("üìπ Video List")

if st.button("üìã Show Video List"):
    all_data = st.session_state.collection.get()
    
    # Group by video
    videos = {}
    if all_data.get('metadatas'):
        for meta in all_data['metadatas']:
            if meta and 'video_id' in meta:
                vid_id = meta['video_id']
                if vid_id not in videos:
                    videos[vid_id] = {
                        'title': meta.get('title', 'N/A'),
                        'date': meta.get('date', 'N/A'),
                        'chunks': 0
                    }
                videos[vid_id]['chunks'] += 1
    
    # Create DataFrame
    video_df = pd.DataFrame([
        {
            'Video ID': vid_id,
            'Title': info['title'],
            'Date': info['date'],
            'Chunks': info['chunks']
        }
        for vid_id, info in sorted(videos.items(), key=lambda x: x[1]['chunks'], reverse=True)
    ])
    
    st.dataframe(
        video_df,
        use_container_width=True,
        height=400
    )
    
    # Download button
    csv = video_df.to_csv(index=False)
    st.download_button(
        label="üì• Download as CSV",
        data=csv,
        file_name="video_list.csv",
        mime="text/csv"
    )

# 3D Visualization section
st.header("üåê 3D Embedding Visualization")

st.markdown("""
Visualizza gli embeddings nello spazio 3D usando riduzione dimensionale (t-SNE/UMAP).
Ogni punto rappresenta un chunk di testo, e i punti vicini hanno contenuti simili.
""")

col_3d1, col_3d2, col_3d3 = st.columns(3)

with col_3d1:
    num_points_3d = st.slider(
        "Number of points to visualize:",
        min_value=100,
        max_value=min(2000, st.session_state.total_docs),
        value=min(500, st.session_state.total_docs),
        step=100
    )
with col_3d2:
    reduction_method = st.selectbox(
        "Reduction method:",
        ["UMAP", "t-SNE"],
        index=0
    )
with col_3d3:
    color_option = st.selectbox(
        "Color by:",
        ["Video ID", "Date", "None"],
        index=0
    )

st.write("")  # Spacing
generate_3d = st.button("üé® Generate 3D Visualization", type="primary", use_container_width=True)

if generate_3d:
    with st.spinner(f"Generating 3D visualization with {num_points_3d} points..."):
        try:
            # Get sample embeddings
            # Note: 'ids' are always returned, don't include them in include parameter
            sample_data = st.session_state.collection.get(
                limit=num_points_3d,
                include=['embeddings', 'metadatas', 'documents']
            )
            
            # Check if embeddings exist and are not empty
            embeddings_list = sample_data.get('embeddings')
            # Handle both list and numpy array cases
            if embeddings_list is None:
                st.error("No embeddings found in database")
            elif hasattr(embeddings_list, '__len__'):
                if len(embeddings_list) == 0:
                    st.error("No embeddings found in database")
                else:
                    embeddings = sample_data['embeddings']
            else:
                st.error("Invalid embeddings format")
                embeddings = None
            
            if embeddings is not None:
                metadatas = sample_data.get('metadatas', [{}] * len(embeddings))
                documents = sample_data.get('documents', [''] * len(embeddings))
                ids = sample_data.get('ids', [''] * len(embeddings))
                
                import numpy as np
                embeddings_array = np.array(embeddings)
                
                # Progress bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Dimensionality reduction
                status_text.text("Reducing dimensions...")
                progress_bar.progress(0.3)
                
                if reduction_method == "UMAP":
                    try:
                        import umap
                        reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=15, min_dist=0.1)
                        reduced_embeddings = reducer.fit_transform(embeddings_array)
                    except ImportError:
                        st.error("UMAP not installed. Install with: pip install umap-learn")
                        st.stop()
                else:  # t-SNE
                    from sklearn.manifold import TSNE
                    status_text.text("Running t-SNE (this may take a while)...")
                    progress_bar.progress(0.5)
                    reducer = TSNE(n_components=3, random_state=42, perplexity=30, n_iter=1000)
                    reduced_embeddings = reducer.fit_transform(embeddings_array)
                
                progress_bar.progress(0.8)
                status_text.text("Preparing visualization...")
                
                # Prepare data for visualization
                x_coords = reduced_embeddings[:, 0]
                y_coords = reduced_embeddings[:, 1]
                z_coords = reduced_embeddings[:, 2]
                
                # Create hover text
                hover_texts = []
                for i, (meta, doc, doc_id) in enumerate(zip(metadatas, documents, ids)):
                    hover_parts = []
                    if meta:
                        if 'title' in meta:
                            hover_parts.append(f"Title: {meta['title'][:50]}")
                        if 'video_id' in meta:
                            hover_parts.append(f"Video: {meta['video_id']}")
                        if 'date' in meta:
                            hover_parts.append(f"Date: {meta['date']}")
                    hover_parts.append(f"Text: {doc[:100]}...")
                    hover_texts.append("<br>".join(hover_parts))
                
                # Color by video_id or date (using the option selected above)
                if color_option == "Video ID":
                    colors = [meta.get('video_id', 'unknown') if meta else 'unknown' for meta in metadatas]
                    color_title = "Video ID"
                elif color_option == "Date":
                    colors = [meta.get('date', 'unknown') if meta else 'unknown' for meta in metadatas]
                    color_title = "Date"
                else:
                    colors = None
                    color_title = None
                
                # Create color mapping for categorical data
                if colors and color_option != "None":
                    # Convert categorical to numeric for colorscale
                    unique_colors = list(set(colors))
                    color_map = {color: i for i, color in enumerate(unique_colors)}
                    numeric_colors = [color_map[c] for c in colors]
                    colorscale = 'Viridis'
                    colorbar_title = color_option
                else:
                    numeric_colors = None
                    colorscale = None
                    colorbar_title = None
                
                # Create 3D scatter plot
                fig = go.Figure(data=go.Scatter3d(
                    x=x_coords,
                    y=y_coords,
                    z=z_coords,
                    mode='markers',
                    marker=dict(
                        size=5,
                        color=numeric_colors if numeric_colors is not None else 'blue',
                        colorscale=colorscale if colorscale else None,
                        opacity=0.7,
                        line=dict(width=0.5, color='white'),
                        colorbar=dict(title=colorbar_title) if colorbar_title else None,
                        showscale=(colorbar_title is not None)
                    ),
                    text=hover_texts,
                    hovertemplate='<b>%{text}</b><extra></extra>',
                    name='Embeddings'
                ))
                
                fig.update_layout(
                    title=f"3D Embedding Space ({reduction_method}) - {num_points_3d} points",
                    scene=dict(
                        xaxis_title="Dimension 1",
                        yaxis_title="Dimension 2",
                        zaxis_title="Dimension 3",
                        bgcolor='rgba(0,0,0,0)',
                        xaxis=dict(backgroundcolor='rgba(0,0,0,0)'),
                        yaxis=dict(backgroundcolor='rgba(0,0,0,0)'),
                        zaxis=dict(backgroundcolor='rgba(0,0,0,0)'),
                    ),
                    width=1000,
                    height=800,
                    margin=dict(l=0, r=0, b=0, t=50)
                )
                
                progress_bar.progress(1.0)
                status_text.text("Visualization ready!")
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Statistics
                st.subheader("üìä 3D Visualization Statistics")
                col_stat1, col_stat2, col_stat3 = st.columns(3)
                with col_stat1:
                    st.metric("Points visualized", num_points_3d)
                with col_stat2:
                    st.metric("Original dimensions", embeddings_array.shape[1])
                with col_stat3:
                    st.metric("Reduced dimensions", 3)
                
                # Download coordinates
                coords_df = pd.DataFrame({
                    'ID': ids,
                    'X': x_coords,
                    'Y': y_coords,
                    'Z': z_coords,
                    'Video ID': [m.get('video_id', '') if m else '' for m in metadatas],
                    'Title': [m.get('title', '') if m else '' for m in metadatas],
                    'Date': [m.get('date', '') if m else '' for m in metadatas]
                })
                
                csv_coords = coords_df.to_csv(index=False)
                st.download_button(
                    label="üì• Download 3D Coordinates (CSV)",
                    data=csv_coords,
                    file_name="embedding_3d_coordinates.csv",
                    mime="text/csv"
                )
        
        except Exception as e:
            st.error(f"Error generating 3D visualization: {e}")
            st.exception(e)

# Footer
st.markdown("---")
st.markdown("**Vector Database Explorer** | Powered by ChromaDB & BGE Embeddings")

